\chapter{Orchestration des applications distribuées}
\begin{onehalfspace}
Docker est un outil qui a révolutionné le monde informatique par l'introduction de la notion de container, donc il est normal de chercher  à l'utiliser en production. De nos jours, les développeurs utilisent de plus en plus Docker pour déployer des applications qui s'éxecutent sur plusieurs conteneurs et plusieurs hôtes. Orchestrer ces applications distribuées nécessite une approche \textbf{multi-conteneur} et \textbf{multi-hôte} native avec une interface utilisateur et de l'outillage commun qui fonctionne sur toutes les infrastructures. Plusieurs outils ont été présentés par de grandes entreprises et sont toujours en cours de développement. Nous exposerons dans ce chapitre les projets promoteurs dans l'orchestration des applications distribuées.
\section{Orchestration Docker}
Les capacités d'orchestration de Docker sont construites sur les fondations de l'engine Docker existante. Ces capacités sont assurées par trois nouveaux services de la plate-forme qui sont conçus pour couvrir tous les aspects du cycle de vie dynamique des applications distribuées. Selon l'entreprise Docker, toutes ces caractéristiques sont conçues avec la philosophie de conception "\emph{Batteries Included, but Removable}" qui indique qu'ils peuvent fonctionner avec des services tierces. Ceci offre le choix aux clients de choisir entre les différents outils d'orchestration de Docker et les alternatives communautaires.
%\begin{figure}[H]
%\centering
%\includegraphics [scale=0.4]{chapitre3/assets/orchestrationdocker.png}
%\caption{Orchestration Docker}
%\end{figure}
\subsection{Docker Machine}
 Ce service facilite le provisionning d'un hôte avec Docker installé dans une variété d'environnements. Les développeurs peuvent rapidement lancer les machines hôtes exécutant Docker ; sur un ordinateur portable, un datacenter de VMs, ou une instance Cloud. Cela évite la tâche de se connecter à un hôte pour installer et configurer le démon Docker et le client. Bien que toujours en version alpha, Docker machine prend en charge le provisionning de Docker localement avec VirtualBox et à distance sur les instances Digital Ocean. Le support pour AWS, Azure, VMware, OpenStack et d'autres infrastructures devrait arriver rapidement.
 \begin{figure}[H]
\centering
\includegraphics [scale=0.6]{chapitre3/assets/dockermachine.png}
\caption{Docker Machine}
\end{figure}
\subsection{Docker Swarm}
 Docker Swarm est un service de clustering natif de Docker qui fonctionne avec l'engine Docker standard, et qui crée un pool de ressources, les hôtes, sur lesquels les applications distribuées s'exécutent. Cela permet aux développeurs et aux équipes opérationnelles de considérer un cluster de machines Docker comme un pool de ressources unique. Les administrateurs peuvent planifier des conteneurs qui seront lancés dans l'un des hôtes qui répond aux exigences. Docker Swarm fournit des contraintes standard et personnalisées pour répondre aux besoins et à la planification basée sur des règles. Cela permet aux administrateurs de déclarer des exigences et contraintes spécifiques à chaque conteneur. Docker Swarm est conçu pour évoluer avec le cycle de vie de l'application. Il peut prendre en charge d'un hôte dans l'environnement de développement à des centaines s'exécutant dans l'environnement de production.
\begin{figure}[H]
\centering
\includegraphics [scale=0.6]{chapitre3/assets/dockerswarm.png}
\caption{Architecture de Docker Swarm}
\end{figure}
\subsection{Docker Compose}
  Docker Composer permet aux développeurs d'assembler des applications de conteneurs Docker autonomes et interopérables et indépendantes de l'infrastructure sous-jacente. Avec cette approche déclarative, il est facile de définir des stacks qui sont portables. Une stack d'applications distribuées est déclarée à travers un simple fichier de configuration \acrshort{yaml} qui contient la définition de chaque conteneur.
\begin{figure}[H]
\centering
\includegraphics [scale=0.5]{chapitre3/assets/dockercompose.jpg}
\caption{Docker Compose}
\end{figure}
\section{Orchestration Google}
L'entreprise Google est aussi interessée par l'orchestration des conteneurs docker, elle a d'ailleurs lancée un projet nommée \textbf{Kubernetes}.Ce projet est récent mais très promoteur et pourrait révolutionner le domaine du Cloud s'il est suffisament mature pour la production. Kubernetes a pour objectif de fournir un outil de supervision unique capable de déplacer des conteneurs Docker d'un cloud à un autre. Autrement dit, de proposer une forme d’interopérabilité dans le nuage, via un framework de gestion des conteneurs solide, ouvert et adapté à toute application sur tous types d’environnements, qu’il s’agisse de Cloud privé, public ou hybride. Ce projet a le soutien et l'attention des géants du cloud notamment Microsoft, IBM, RedHat qui tiennent à s'assurer que cet outil sera compatible avec leurs clouds et l'associer au projet \textbf{Openstack} qui est l'orchestrateur du cloud hybride open source.
\subsection{Architecture de Kubernetes}
Kubernetes est un outil open-source pour l'orchestration des conteneurs Docker. Il gère l'ordonnancement des noeuds dans un \textbf{cluster} et gère les ressources pour mieux correspondre à l'intention de l'utilisateur. En Utilisant les concepts de "\emph{labels}" et "\emph{pods}", il permet un regroupement optimal des conteneurs pour une meilleure gestion et une découverte facile.
\begin{figure}[H]
\centering
\includegraphics [scale=0.5]{chapitre3/assets/archkuber.png}
\caption{Architecture de Kubernetes}
\end{figure}

\begin{itemize}
\item \textbf{Kubernetes Master} : Il contrôle l'ensemble du cluster et exécute l'API pour le cluster. Fondamentalement, il est responsable du cluster.

\item \textbf{Nodes} : Un nœud est un serveur physique (ou une machine virtuelle ) à l'intérieur du cluster. Il communique avec les maîtres et contient des conteneurs, on peut ajouter ou supprimer des noeuds à volonté.

\item \textbf{Pods} : Un "Pod" est le bloque basique de construction dans \emph{Kubernetes}.Dans un pod, il est possible de lancer plusieurs conteneurs. L'allocation des CPU, mémoire et des autres ressources est gérée dans un pod. Chaque pod possède sa propre adresse ip et son nom d'hôte pour éviter d'éventuels conflicts de ports.

\item \textbf{Replication Controller} : Il est vrai que le Pod est un composant puissant au sein de \emph{Kubernetes} mais il ne permet pas la gestion des échecs. Les échecs sont des événements inévitables bien qu'il faudrait que le service soit toujours disponible. c'est de ce fait qu'intervient \emph{Replication Controller}. Ce dernier s'assure qu'un nombre donné de pods sont exécutés au sein du cluster , il peut enlever et ajouter des pods du cluster donc il faudra définir un pod template pour assurer sa fonction.

\item \textbf{Services} : les Pods sont ajoutés ou supprimés donc il faudrait permettre un \textbf{load-balancing} du traffic dans ses pods. "\emph{Service}" agit comme un \emph{load-balancer} dynamique pour un ensemble de pods, il est très efficace et utilise différentes techniques ( IP Tables, ...) pour éviter la surchage.

\end{itemize}
\begin{figure}[H]
\centering
\includegraphics [scale=0.5]{chapitre3/assets/kuber.png}
\caption{Résumé de Kubernetes}
\end{figure}

 

\end{onehalfspace}